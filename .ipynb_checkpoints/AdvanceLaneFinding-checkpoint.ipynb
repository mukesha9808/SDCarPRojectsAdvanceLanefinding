{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate camera calibration\n",
    "This section calculate distortion matrix using chessboard images. multiple chessboard images used to determine distortion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "    \n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        \n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistort image function\n",
    "Undistort imgae using calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_image(distorted_image):\n",
    "    #Correct distortion using matrix from previous cell\n",
    "    \n",
    "    undist = cv2.undistort(distorted_image, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process chessboard images for distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1 = glob.glob('./camera_cal/calibration*.jpg')\n",
    "for fname1 in images1:\n",
    "    #image output name\n",
    "    filename=os.path.split(fname1)[-1]\n",
    "    outfile='./output_images/' + filename +'.jpg'\n",
    "    \n",
    "    #read image in pipeline\n",
    "    img1 = cv2.imread(fname1)\n",
    "    undist = cv2.undistort(img1, mtx, dist, None, mtx)\n",
    "\n",
    "    #Process image and save\n",
    "    '''f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(undist)\n",
    "    ax2.set_title('Undistorted Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    f.savefig(outfile)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image thresholding\n",
    "I am using s channel for color thresholding and experimenting multiple channels on test images and then evaluate best channel to use gradient. I have decided to combine  s channel color threshold and s-channel x gradient and direction gradient to filter out pixels in horizontal direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_binary(img_rgb,sthresh,sxthresh,gradthresh):\n",
    "    \n",
    "    #convert color into HLS\n",
    "    img_hls = cv2.cvtColor(img_rgb,cv2.COLOR_RGB2HLS)\n",
    "    img_s=img_hls[:,:,2]\n",
    "    img_l=img_hls[:,:,1]\n",
    "    \n",
    "    #Create binary based on color thresholding\n",
    "    s_binary = np.zeros_like(img_s)\n",
    "    s_binary[(img_s >= sthresh[0]) & (img_s <= sthresh[1])]=1\n",
    "    \n",
    "    #Gradient thresholding\n",
    "    #Kernel Size\n",
    "    sobel_kernel=5\n",
    "    \n",
    "    #S-Channel  gradient threshold\n",
    "    sobel_sx=cv2.Sobel(img_s, cv2.CV_64F, 1, 0,ksize=sobel_kernel)\n",
    "    sobel_sy=cv2.Sobel(img_s, cv2.CV_64F, 0, 1,ksize=sobel_kernel)\n",
    "    abs_sobel_sx = np.absolute(sobel_sx) \n",
    "    scaled_sobels_sx = np.uint8(255*abs_sobel_sx/np.max(abs_sobel_sx))\n",
    "    #Create S-channel binary\n",
    "    sx_binary = np.zeros_like(scaled_sobels_sx)\n",
    "    sx_binary[(scaled_sobels_sx >= sxthresh[0]) & (scaled_sobels_sx <= sxthresh[1]) ] = 1\n",
    "    \n",
    "    #S-Channel direction threshold\n",
    "    absgraddir = np.arctan2(np.absolute(sobel_sy), np.absolute(sobel_sx))\n",
    "    binary_output =  np.zeros_like(scaled_sobels_sx)\n",
    "    binary_output[(absgraddir >= gradthresh[0]) & (absgraddir <= gradthresh[1])] = 1\n",
    "    \n",
    "    #Plotting each thresholding\n",
    "    '''Combined=np.dstack((s_binary,sx_binary,binary_output))*255\n",
    "    plt.imshow(Combined)\n",
    "    plt.show()\n",
    "    cv2.putText(Combined,'S-Channel colour thresholding', (200,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0),2)\n",
    "    cv2.putText(Combined,'X direction mag threshold on S-Channel', (200,80),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),2) \n",
    "    cv2.putText(Combined,'Direction threshold between 0 to PI/3(Red channels)', (200,110),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2) \n",
    "    cv2.imwrite('./output_images/gradien_distribution.jpg',Combined)'''\n",
    "    \n",
    "    binary=np.zeros_like(sx_binary)\n",
    "    binary[((s_binary == 1) | (sx_binary == 1)) & (binary_output==1)] =1\n",
    "    \n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform image\n",
    "Image perspective transformation to top down view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(src_image,src,dst):\n",
    "    #Transform imarge to top down view\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(src_image, M, (src_image.shape[1],src_image.shape[0]))\n",
    "    return warped, M, Minv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(warp_img):\n",
    "    # Grab only the bottom half of the image\n",
    "    # Lane lines are likely to be mostly vertical nearest to the car\n",
    "    bottom_half = warp_img[warp_img.shape[0]//2:,:]\n",
    "\n",
    "    # Sum across image pixels vertically - make sure to set an `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window search\n",
    "Find lane in frame using sliding window search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slidingwindow_search(bin_img,hist):\n",
    "    #Determine left and right line start place for search\n",
    "    img_midpoint=hist.shape[0]//2\n",
    "    left_start_x=np.argmax(hist[:img_midpoint])\n",
    "    right_start_x=np.argmax(hist[img_midpoint:])+img_midpoint\n",
    "    \n",
    "    #Heperparameter\n",
    "    nwindows=10\n",
    "    winmargin=100\n",
    "    minpix=40\n",
    "    maxpix=7000\n",
    "    winheight=np.int(bin_img.shape[0]/nwindows)\n",
    "    \n",
    "    #List for collecting lane pixels\n",
    "    left_lane_ids=[]\n",
    "    right_lane_ids=[]\n",
    "    \n",
    "    #Nonzero pixels in image\n",
    "    bin_img_nonzero=bin_img.nonzero()\n",
    "    bin_img_nonzeroy=np.array(bin_img_nonzero[0])\n",
    "    bin_img_nonzerox=np.array(bin_img_nonzero[1])\n",
    "    \n",
    "    #Ploting\n",
    "    out_img = np.dstack((bin_img, bin_img, bin_img))*255\n",
    "    \n",
    "    \n",
    "    \n",
    "    #looping window\n",
    "    currentx_l=left_start_x\n",
    "    currentx_r=right_start_x\n",
    "    \n",
    "    #print(currentx_l)\n",
    "    #print(currentx_r)\n",
    "    \n",
    "    for window in range(nwindows):\n",
    "        win_yl=bin_img.shape[0]-(window+1)*winheight\n",
    "        win_yh=bin_img.shape[0]-(window)*winheight\n",
    "        leftwin_xl=currentx_l-winmargin\n",
    "        leftwin_xh=currentx_l+winmargin\n",
    "        rightwin_xl=currentx_r-winmargin\n",
    "        rightwin_xh=currentx_r+winmargin\n",
    "        \n",
    "        #ploting\n",
    "        cv2.rectangle(out_img,(leftwin_xl,win_yl), (leftwin_xh,win_yh),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(rightwin_xl,win_yl), (rightwin_xh,win_yh),(0,255,0), 2) \n",
    "        \n",
    "        left_good_ids=((bin_img_nonzeroy <= win_yh) & (bin_img_nonzeroy >= win_yl) \n",
    "                      & (bin_img_nonzerox >= leftwin_xl) &(bin_img_nonzerox <= leftwin_xh)).nonzero()[0]\n",
    "        \n",
    "        \n",
    "        right_good_ids=((bin_img_nonzeroy <= win_yh) & (bin_img_nonzeroy >= win_yl) \n",
    "                      & (bin_img_nonzerox >= rightwin_xl) &(bin_img_nonzerox <= rightwin_xh)).nonzero()[0]\n",
    "        \n",
    "        \n",
    "        #append points\n",
    "        left_lane_ids.append(left_good_ids)\n",
    "        right_lane_ids.append(right_good_ids)\n",
    "        \n",
    "       \n",
    "        #check if points are good enough for update box centre\n",
    "        if (((len(left_good_ids) > minpix)) \n",
    "            & ((len(right_good_ids) > minpix) )):\n",
    "            \n",
    "            currentx_l=np.int(np.mean(bin_img_nonzerox[left_good_ids]))\n",
    "            currentx_r=np.int(np.mean(bin_img_nonzerox[right_good_ids]))\n",
    "            #print(\"both\")\n",
    "            #print(currentx_l)\n",
    "            #print(currentx_r)\n",
    "        elif ((len(left_good_ids) > minpix) ):\n",
    "            temp_x=np.int(np.mean(bin_img_nonzerox[left_good_ids]))\n",
    "            delta=temp_x-currentx_l\n",
    "            currentx_l=temp_x\n",
    "            currentx_r=currentx_r+delta\n",
    "            #print(\"Only left\")\n",
    "            #print(currentx_l)\n",
    "            #print(currentx_r)\n",
    "        elif ((len(right_good_ids) > minpix) ):\n",
    "            temp_y=np.int(np.mean(bin_img_nonzerox[right_good_ids]))\n",
    "            delta=temp_y-currentx_r\n",
    "            currentx_l=currentx_l+delta\n",
    "            currentx_r=temp_y\n",
    "            #print(\"Only right\")\n",
    "            #print(currentx_l)\n",
    "            #print(currentx_r)\n",
    "            \n",
    "       \n",
    "    #plt.imshow(out_img)\n",
    "    #plt.show()\n",
    "    \n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_ids = np.concatenate(left_lane_ids)\n",
    "        right_lane_ids = np.concatenate(right_lane_ids)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "    \n",
    "    #Extract pixel positions\n",
    "    leftx=bin_img_nonzerox[left_lane_ids]\n",
    "    lefty=bin_img_nonzeroy[left_lane_ids]\n",
    "    rightx=bin_img_nonzerox[right_lane_ids]\n",
    "    righty=bin_img_nonzeroy[right_lane_ids]\n",
    "\n",
    "    return leftx, lefty, rightx, righty\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate xy for polynimoial plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def ploty_poly(image_ploty,left_fit_plt,right_fit_plt, leftx_plt, lefty_plt, rightx_plt, righty_plt):\n",
    "    # Generate x and y values for plotting\n",
    "    \n",
    "    ploty = np.linspace(0, image_ploty.shape[0]-1, image_ploty.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit_plt[0]*ploty**2 + left_fit_plt[1]*ploty + left_fit_plt[2]\n",
    "        right_fitx = right_fit_plt[0]*ploty**2 + right_fit_plt[1]*ploty + right_fit_plt[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    #print(leftx_plt)\n",
    "    #print(rightx_plt)\n",
    "    poly_img=np.dstack((np.zeros_like(image_ploty),np.zeros_like(image_ploty),image_ploty))\n",
    "    poly_img[lefty_plt,leftx_plt,]=[255,0,0]\n",
    "    poly_img[righty_plt,rightx_plt]=[0,0,255]\n",
    "    #Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    #plt.imshow(poly_img)\n",
    "    #plt.show()\n",
    "    '''fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(poly_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    fig.savefig('./output_images/fitted_polyline.jpg')\n",
    "    '''    \n",
    "    \n",
    "    return left_fitx, right_fitx, ploty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial fit\n",
    "Fiting pixels into second order polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(input_image,leftx, lefty, rightx, righty):\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    left_fitx,right_fitx, ploty =ploty_poly(input_image,left_fit,right_fit, leftx, lefty, rightx, righty)\n",
    "       \n",
    "        \n",
    "    return left_fit, right_fit, left_fitx, right_fitx\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the lane using polynomial in previous frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_around_poly(binary_warped,prev_left_fit,prev_right_fit):\n",
    "    # HYPERPARAMETER\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    left_lane_inds_ = ((nonzerox > (prev_left_fit[0]*(nonzeroy**2) + prev_left_fit[1]*nonzeroy + \n",
    "                    prev_left_fit[2] - margin)) & (nonzerox < (prev_left_fit[0]*(nonzeroy**2) + \n",
    "                    prev_left_fit[1]*nonzeroy + prev_left_fit[2] + margin)))\n",
    "    right_lane_inds_ = ((nonzerox > (prev_right_fit[0]*(nonzeroy**2) + prev_right_fit[1]*nonzeroy + \n",
    "                    prev_right_fit[2] - margin)) & (nonzerox < (prev_right_fit[0]*(nonzeroy**2) + \n",
    "                    prev_right_fit[1]*nonzeroy + prev_right_fit[2] + margin)))\n",
    "    \n",
    "    # extract left and right line pixel positions\n",
    "    leftx_polysearch = nonzerox[left_lane_inds_]\n",
    "    lefty_polysearch = nonzeroy[left_lane_inds_] \n",
    "    rightx_polysearch = nonzerox[right_lane_inds_]\n",
    "    righty_polysearch = nonzeroy[right_lane_inds_]\n",
    "    \n",
    "    if((len(leftx_polysearch) > 2) & (len(lefty_polysearch) > 2) & (len(rightx_polysearch) > 2) & (len(righty_polysearch) > 2)):\n",
    "        \n",
    "        # Fit new polynomials\n",
    "        left_fit_, right_fit_ , left_fitx, right_fitx = fit_polynomial(binary_warped, leftx_polysearch, lefty_polysearch, rightx_polysearch, righty_polysearch)\n",
    "\n",
    "\n",
    "        left_fiteedx, right_fittedx, ploty_ =ploty_poly(binary_warped,left_fit_,right_fit_,\\\n",
    "                                                 leftx_polysearch, lefty_polysearch, rightx_polysearch, righty_polysearch)\n",
    "    else:\n",
    "        left_fit_=prev_left_fit\n",
    "        right_fit_=prev_right_fit\n",
    "        left_fiteedx=[]\n",
    "        right_fittedx=[]\n",
    "\n",
    "    return left_fit_, right_fit_, left_fiteedx, right_fittedx, leftx_polysearch, lefty_polysearch, rightx_polysearch, righty_polysearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert pixel polynomial into real world polynomial\n",
    "Convert polynomial into ral world polynomial equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_poly2realworld(leftfit_pix,right_fit_pix,x_pix2realworl, y_pix2realworld):\n",
    "    leftfit_real=[0 for x in range(3)]\n",
    "    rightfit_real=[0 for x in range(3)]\n",
    "    \n",
    "    leftfit_real[0]=(leftfit_pix[0]*x_pix2realworl)/(y_pix2realworld**2)\n",
    "    leftfit_real[1]=(leftfit_pix[1]*x_pix2realworl)/(y_pix2realworld)\n",
    "    leftfit_real[2]=(leftfit_pix[2]*x_pix2realworl)\n",
    "    \n",
    "    rightfit_real[0]=(right_fit_pix[0]*x_pix2realworl)/(y_pix2realworld**2)\n",
    "    rightfit_real[1]=(right_fit_pix[1]*x_pix2realworl)/(y_pix2realworld)\n",
    "    rightfit_real[2]=(right_fit_pix[2]*x_pix2realworl)\n",
    "    \n",
    "    return leftfit_real, rightfit_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure radius of curvature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meas_curvature(left_fitpoly,right_fitply,y_instance):\n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fitpoly[0]*y_instance + left_fitpoly[1])**2)**1.5) / np.absolute(2*left_fitpoly[0])\n",
    "    right_curverad = ((1 + (2*right_fitply[0]*y_instance + right_fitply[1])**2)**1.5) / np.absolute(2*right_fitply[0])\n",
    "    \n",
    "    return left_curverad,right_curverad\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane drawn on road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image(src_img,im_warped,im_left_fitx,im_right_fitx,im_ploty,Minv,text1,text2):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(im_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([im_left_fitx, im_ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([im_right_fitx, im_ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (im_warped.shape[1], im_warped.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(src_img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    cv2.putText(result,text1, (200,50),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
    "    cv2.putText(result,text2, (200,80),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)            \n",
    "    #plt.imshow(result)\n",
    "    #plt.show()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = np.array([0,0,0], dtype='float')   \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx =[]\n",
    "        #y values for detected line pixels\n",
    "        self.ally = []\n",
    "        #number of frame missed\n",
    "        self.missed=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_lane=Line()\n",
    "right_lane=Line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process image\n",
    "Crearte a fiunction to process image in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(movie_img):\n",
    "    #Covert image into BGR\n",
    "    movie_rgb= cv2.cvtColor(movie_img,cv2.COLOR_BGR2RGB)\n",
    "    #plt.imshow(movie_rgb)\n",
    "    #plt.show()\n",
    "    \n",
    "    #Distortion correction\n",
    "    undist_img=undistort_image(movie_rgb)\n",
    "    \n",
    "    \n",
    "    #Binary image after gradient and color thresholding\n",
    "    colr_thres=(140,255)\n",
    "    grad_mag_thres=(20,100)\n",
    "    grad_dir_thres=(0,np.pi/3)\n",
    "    grad_img=get_image_binary(undist_img,colr_thres,grad_mag_thres,grad_dir_thres)\n",
    "    #plt.imshow(grad_img)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    #Perspective transformation\n",
    "    src_corners = np.array([[592,450], [690,450], [1070,700], [245,700]])\n",
    "    dst_corners = np.array([[200,100], [1000,100], [1000,650], [200,650]])\n",
    "    \n",
    "    #Plot region of interest for transformation\n",
    "    gradout=np.dstack((np.zeros_like(grad_img),np.zeros_like(grad_img),grad_img))*255\n",
    "    \n",
    "    cv2.polylines(gradout, [dst_corners], 1, (255,0,0),4)\n",
    "    #plt.imshow(gradout)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    #image to top down\n",
    "    warped_img, M_warped, Minv_warpd =transform_image(grad_img,np.float32(src_corners),np.float32(dst_corners))\n",
    "    \n",
    "    \n",
    "    warp_zero = np.zeros_like(warped_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warped_img))*255\n",
    "    #plt.imshow(color_warp)\n",
    "    #plt.show()\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv_warpd, (color_warp.shape[1], color_warp.shape[0])) \n",
    "    #plt.imshow(newwarp)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    #top down image plot\n",
    "    warpout=np.dstack((np.zeros_like(warped_img),np.zeros_like(warped_img),warped_img))*255\n",
    "    #cv2.rectangle(warpout,(200,100), (1000,650),(255,0,0), 2) \n",
    "    #plt.imshow(warpout)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    #Search sliding window if line detected is not true\n",
    "    if ((left_lane.detected == False) | (right_lane.detected == False)):\n",
    "        #print('Sliding window search')\n",
    "        \n",
    "        #Historgram for finding best place to start\n",
    "        histogram=hist(warped_img/255)\n",
    "        \n",
    "        #Search lane pixelusing sliding window search\n",
    "        leftx_i, lefty_i, rightx_i, righty_i=slidingwindow_search(warped_img,histogram)\n",
    "        \n",
    "             \n",
    "        #Store detected pixel cordinates for left lane\n",
    "        left_lane.allx.append(leftx_i)\n",
    "        left_lane.ally.append(lefty_i)\n",
    "\n",
    "        #Store detected pixel cordinates for right lane\n",
    "        right_lane.allx.append(rightx_i)\n",
    "        right_lane.ally.append(righty_i)\n",
    "        \n",
    "        \n",
    "        last_nxleft=np.concatenate((left_lane.allx[-10:]))\n",
    "        last_nyleft=np.concatenate((left_lane.ally[-10:]))\n",
    "        last_nxright=np.concatenate((right_lane.allx[-10:]))\n",
    "        last_nyright=np.concatenate((right_lane.ally[-10:]))\n",
    "        \n",
    "        #Procedd further only if two points atleast detected\n",
    "        if ((len(last_nxleft) >2) & (len(last_nyleft) >2) &\n",
    "           (len(last_nxright) >2) & (len(last_nxright) >2)):\n",
    "            \n",
    "            #fit polynimial \n",
    "            left_lane.current_fit,right_lane.current_fit,left_current_xfitted, right_current_xfitted = fit_polynomial(\n",
    "                warped_img,last_nxleft, last_nyleft,last_nxright, last_nyright)\n",
    "            \n",
    "    else:\n",
    "        #print('Around Poly search')\n",
    "        \n",
    "        #Search lane around the existing polynomial\n",
    "        left_lane.current_fit,right_lane.current_fit,\\\n",
    "        left_current_xfitted, right_current_xfitted, \\\n",
    "        leftx_i, lefty_i, rightx_i, righty_i = search_around_poly(warped_img,left_lane.best_fit,right_lane.best_fit)\n",
    "        \n",
    "        \n",
    "        #Store detected pixel cordinates for left lane\n",
    "        left_lane.allx.append(leftx_i)\n",
    "        left_lane.ally.append(lefty_i)\n",
    "                \n",
    "        #Store detected pixel cordinates for right lane\n",
    "        right_lane.allx.append(rightx_i)\n",
    "        right_lane.ally.append(righty_i)\n",
    "        \n",
    "    \n",
    "      \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 35/640 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/850 # meters per pixel in x dimension\n",
    "    left_fit_real,right_fit_real = convert_poly2realworld(left_lane.current_fit,right_lane.current_fit,xm_per_pix, ym_per_pix)\n",
    "    \n",
    "    #Measure curvature at y=700\n",
    "    left_curv,right_curv=meas_curvature(left_fit_real,right_fit_real,700)\n",
    "    \n",
    "    #print('leftcur',left_curv,'right cur',right_curv)\n",
    "    #Sanity check of detcted line\n",
    "    # if mean difference in fited x are more than 50 pixel then line may not beparalle\n",
    "    # if curvature is too high then fitting is wrong\n",
    "    #if both lane curvature differing too much then fitting is wrong\n",
    "    #print((np.mean(right_current_xfitted-(left_current_xfitted+800))))\n",
    "    #print(np.maximum(left_curv,right_curv))\n",
    "    #print(np.abs(left_curv-right_curv))\n",
    "    \n",
    "    if ((len(right_current_xfitted)==0) | (len(left_current_xfitted)==0)):\n",
    "        #increase missed frame count\n",
    "        left_lane.missed=left_lane.missed+1\n",
    "        right_lane.missed=right_lane.missed+1\n",
    "        \n",
    "        out_image=movie_img\n",
    "        \n",
    "    elif (np.abs(np.mean(right_current_xfitted-(left_current_xfitted+800)) > 100)\\\n",
    "    | (np.maximum(left_curv,right_curv) > 15000.)  | (np.abs(left_curv-right_curv) > 12000.)):\n",
    "        #print('Lane Missed')\n",
    "        \n",
    "        #increase missed frame count\n",
    "        left_lane.missed=left_lane.missed+1\n",
    "        right_lane.missed=right_lane.missed+1\n",
    "        \n",
    "        out_image=movie_img\n",
    "    else:\n",
    "        #print('Lane found')\n",
    "        \n",
    "        #reset missed frame count\n",
    "        left_lane.missed=0\n",
    "        right_lane.missed=0\n",
    "        \n",
    "        #Set lane detected\n",
    "        left_lane.detected=True\n",
    "        right_lane.detected=True\n",
    "        \n",
    "         # x values of the last n fits of the line\n",
    "        left_lane.recent_xfitted.append(left_current_xfitted)\n",
    "        right_lane.recent_xfitted.append(right_current_xfitted)\n",
    "        \n",
    "        \n",
    "        #store only 10 values\n",
    "        if(len(left_lane.recent_xfitted)>10):\n",
    "            left_lane.recent_xfitted.pop(0)\n",
    "        if(len(right_lane.recent_xfitted)>10):\n",
    "            right_lane.recent_xfitted.pop(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        left_lane.bestx = np.mean([left_lane.recent_xfitted], axis=0)\n",
    "        right_lane.bestx = np.mean([right_lane.recent_xfitted], axis=0)\n",
    "        \n",
    "               \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        left_lane.diffs = left_lane.best_fit - left_lane.current_fit\n",
    "        right_lane.diffs =right_lane.best_fit - right_lane.current_fit\n",
    "        \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        if (all(left_lane.best_fit == 0)):\n",
    "            left_lane.best_fit = left_lane.current_fit\n",
    "        else:\n",
    "            left_lane.best_fit = (left_lane.best_fit + left_lane.current_fit)/2\n",
    "        \n",
    "        if (all(right_lane.best_fit == 0)):\n",
    "            right_lane.best_fit = right_lane.current_fit\n",
    "        else:\n",
    "            right_lane.best_fit = (right_lane.best_fit + right_lane.current_fit)/2\n",
    "                \n",
    "                                               \n",
    "        #radius of curvature of the line in some units\n",
    "        left_lane.radius_of_curvature = left_curv \n",
    "        right_lane.radius_of_curvature = right_curv \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(left_lane.line_base_pos)\n",
    "        #print(right_lane.line_base_pos)\n",
    "        last_nxright=np.concatenate((right_lane.allx[-10:]))\n",
    "        last_nyright=np.concatenate((right_lane.ally[-10:]))\n",
    "        last_nxleft=np.concatenate((left_lane.allx[-10:]))\n",
    "        last_nyleft=np.concatenate((left_lane.ally[-10:]))\n",
    "        \n",
    "        xfitted_left, xfitted_right,ploty_current=ploty_poly(\n",
    "            warped_img,left_lane.best_fit ,right_lane.best_fit,last_nxleft,last_nyleft,last_nxright,last_nyright)\n",
    "        \n",
    "        #print(movie_img.shape[1]/2)\n",
    "        #print(xfitted_left[-1])\n",
    "        #print(xfitted_right[-1])\n",
    "        #distance in meters of vehicle center from the line\n",
    "        left_lane.line_base_pos= ((movie_img.shape[1]/2)-xfitted_left[-1])* xm_per_pix \n",
    "        right_lane.line_base_pos= (xfitted_right[-1] -(movie_img.shape[1]/2))* xm_per_pix\n",
    "        #print(left_lane.line_base_pos)\n",
    "        #print(right_lane.line_base_pos)\n",
    "        \n",
    "        #Print Text\n",
    "        text_radcurv='Radius of Curvature = ' +str(round(np.minimum(left_curv,right_curv),1)) + '(m)'\n",
    "        if (left_lane.line_base_pos == right_lane.line_base_pos ):\n",
    "            text_centr='vehicle is in center of lane'\n",
    "        elif(left_lane.line_base_pos < right_lane.line_base_pos ):\n",
    "            text_centr='vehicle is '+ str(round((right_lane.line_base_pos- left_lane.line_base_pos),2)) +'m left of center'\n",
    "        else:\n",
    "            text_centr='vehicle is '+str(round((left_lane.line_base_pos - right_lane.line_base_pos),2)) +'m right of center'\n",
    "        \n",
    "        #plt.imshow(warped_img)\n",
    "        #plt.show()\n",
    "        out_image = draw_image(movie_img,warped_img,xfitted_left,xfitted_right,ploty_current,Minv_warpd,text_radcurv, text_centr)\n",
    "        \n",
    "        \n",
    "    if ((left_lane.missed >=5 ) | (right_lane.missed >=5 )):\n",
    "        left_lane.detected=False\n",
    "        right_lane.detected=False\n",
    "    \n",
    "    return out_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test image pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of calibration images\n",
    "images = glob.glob('./test_images/*.jpg')\n",
    "print(images)\n",
    "for fim in images:\n",
    "    print(fim)\n",
    "    left_lane=Line()\n",
    "    right_lane=Line()\n",
    "    curimage=cv2.imread(images[6])\n",
    "  \n",
    "    x = process_image(curimage)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = './output_video/project_video1.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,0.02)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "left_lane=Line()\n",
    "right_lane=Line()\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(test_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = './output_video/challenge_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,1)\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "left_lane=Line()\n",
    "right_lane=Line()\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(test_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harder Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = './output_video/harder_challenge_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,1)\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "left_lane=Line()\n",
    "right_lane=Line()\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
